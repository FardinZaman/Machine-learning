# -*- coding: utf-8 -*-
"""Viterbi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11d9yoKxE7MLImL2C-UTLL9OkXxrJV4s4
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd /content/gdrive/MyDrive/Viterbi/

import numpy as np
from scipy.stats import norm
import scipy.linalg as la

observations = []
N = 0
states = []
transition_matrix = []
gaussian_means = []
gaussian_standard_deviations = []
emission_matrix = []
initial_probabilities = []
pi_vector = []
transition_matrix_changed = []
emission_matrix_changed = []
pi_vector2 = []
# means_changed = []
# standard_deviations_changed = []

with open('data.txt') as file:
    for readline in file:
        observations.append(float(readline.strip()))

print(observations)

with open('parameters.txt') as file:
    N = int(file.readline())

    for i in range(N):
        states.append(i)
    # print(states)

    for i in range(N):
        line = file.readline()
        one_row = []
        for element in line.split():
            one_row.append(float(element.strip()))
        
        #print(one_row)
        transition_matrix.append(one_row)
        #print(transition_matrix)

    line = file.readline()
    for element in line.split():
        gaussian_means.append(float(element.strip()))

    line = file.readline()
    for element in line.split():
        gaussian_standard_deviations.append(float(element.strip()))

# print(gaussian_means)
# print(gaussian_standard_deviations)

def gaussian_distribution(x, mean, standard_deviation):
    return norm.pdf(x, loc=mean, scale=np.sqrt(standard_deviation))

def gaussian_distribution2(x, mean, standard_deviation):
    return norm.pdf(x, loc=mean, scale=standard_deviation)

for state in states:
    one_row_again = []
    for observation in observations:
        probability = gaussian_distribution(observation , gaussian_means[state] , gaussian_standard_deviations[state])
        one_row_again.append(probability)
    
    emission_matrix.append(one_row_again)

print(emission_matrix)

#initial_probabilities = np.linalg.eig(transition_matrix)[0]
#print(transition_matrix)
#print(initial_probabilities)
#eigen_values, eigen_vectors = np.linalg.eig(transition_matrix.T)
eigen_values, eigen_vectors = la.eig(transition_matrix , left=True , right=False)
initial_probabilities = eigen_vectors[: , np.isclose(eigen_values , 1)]
initial_probabilities = initial_probabilities[:,0]
pi_vector = initial_probabilities / initial_probabilities.sum()

print(pi_vector)

def viterbi(observations , states, pi_vector , transition_matrix, emission_matrix):
    
    length = len(observations)

    probability_table = np.array([[float(0)] * length] * N)
    previous_states_table = np.array([[-1] * length] * N)

    
    for state in states:
        #probability_table[state][0] = np.log(pi_vector[state] * gaussian_distribution(observations[0], gaussian_means[state], gaussian_standard_deviations[state]))
        probability_table[state][0] = np.log(pi_vector[state] * emission_matrix[state][0])

    # print(probability_table)

    for i in range(1 , length):
        
        for current_state in states:
            maximum_probability = float('-inf')
            previous_state = -1

            for previous in states:
                counted_probability = probability_table[previous][i-1] + np.log(transition_matrix[previous][current_state])
                
                if counted_probability > maximum_probability:
                    maximum_probability = counted_probability
                    previous_state = previous

            
            maximum_probability = maximum_probability + np.log(emission_matrix[current_state][i])

            probability_table[current_state][i] = maximum_probability
            previous_states_table[current_state][i] = previous_state

    # print(probability_table)
    # print(previous_states_table)
    

    maximum_last_column = float('-inf')
    highest = -1

    predicted_seuquence = []
    prev = -1

    for i in range(N):
        if probability_table[i][length-1] > maximum_last_column:
            maximum_last_column = probability_table[i][length-1]
            highest = i

    predicted_seuquence.append(highest)
    prev = highest

    for i in range(length-2 , -1 , -1):
        predicted_seuquence.insert(0, previous_states_table[prev][i+1])
        prev = previous_states_table[prev][i+1]

    return predicted_seuquence


sequence = viterbi(observations, states, pi_vector, transition_matrix, emission_matrix)

filename = 'states_Viterbi_wo_learning.txt'

f = open(filename, "w")

one, zero = 0, 0
for s in sequence:
    if(s == 0):
        #print('"El Nino"')
        f.write('\"El Nino\"\n')
        zero += 1
    else:
        #print('"La Nina"')
        f.write('\"La Nina\"\n')
        one += 1

print(zero, one)
print(len(sequence))

f.close()

# result_container = [0]*N
# for s in sequence:
#   for i in range(N):
#     if s==states[i]:
#       result_container[i] += 1

# print(result_container)

coefficients = np.array([0.0]*len(observations))
means_changed = np.array([0.0]*N)
standard_deviations_changed = np.array([0.0]*N)
#coefficients.shape

def forward_phase(transition_matrix , pi_vector , emission_matrix):
    length = len(observations)
    alpha_matrix = np.array([[float(0)]*length]*N)

    for i in range(N):
        alpha_matrix[i][0] = pi_vector[i] * emission_matrix[i][0]
        # print(pi_vector[i])
        # print(emission_matrix[i][0])
        # print(alpha_matrix[i][0])

    coefficients[0] = 1.0 / np.sum(alpha_matrix[: , 0])
    # print(coefficients[0])
    
    for i in range(N):
        alpha_matrix[i][0] = alpha_matrix[i][0] * coefficients[0]
        # print(alpha_matrix[i][0])
            
    for j in range(1 , length):
        for i in range(N):
            for k in range(N):
                one_state = alpha_matrix[k][j-1] * transition_matrix[k][i] * emission_matrix[i][j]
                alpha_matrix[i][j] = alpha_matrix[i][j] + one_state

        coefficients[j] = 1.0 / np.sum(alpha_matrix[: , j])
        
        for i in range(N):
            alpha_matrix[i][j] = alpha_matrix[i][j] * coefficients[j]
    
    return alpha_matrix


def backward_phase(transition_matrix , emission_matrix):
    length = len(observations)
    beta_matrix = np.array([[float(0)]*length]*N)

    for i in range(N):
        beta_matrix[i][length-1] = 1.0

    for j in range(length-2, -1, -1):
        for i in range(N):
            for k in range(N):
                one_state = beta_matrix[k][j+1] * transition_matrix[i][k] * emission_matrix[k][j+1]
                beta_matrix[i][j] = beta_matrix[i][j] + one_state
            
            beta_matrix[i][j] = beta_matrix[i][j] * coefficients[j]
    
    return beta_matrix


# alpha_incoming = forward_phase()
# beta_incoming = backward_phase()

# print(alpha_incoming)
# print(alpha_incoming[0][0])
# print(alpha_incoming[1][0])
# print(beta_incoming)
# print(coefficients)

for i in range(N):
  one_row = []
  for j in range(N):
    one_row.append(transition_matrix[i][j])
  transition_matrix_changed.append(one_row)

# print(transition_matrix_changed)

for i in range(N):
  one_row = []
  for j in range(len(observations)):
    one_row.append(emission_matrix[i][j])
  emission_matrix_changed.append(one_row)

# print(emission_matrix_changed)

def update_phase(alpha_incoming , beta_incoming):
  length  = len(observations)

  for i in range(N):
    for j in range(N):
      upper_part = 0.0
      lower_part = 0.0

      for t in range(0 , length-1):
        # print(upper_part , "/" , lower_part)
        all_multiplied = alpha_incoming[i][t] * beta_incoming[j][t+1] * transition_matrix_changed[i][j] * emission_matrix_changed[j][t+1]
        # all_multiplied = np.log(alpha_incoming[i][t]) + np.log(beta_incoming[j][t+1]) + np.log(transition_matrix_changed[i][j]) + np.log(emission_matrix_changed[j][t+1])
        # print(all_multiplied)
        # print(alpha_incoming[i][t])
        # print(transition_matrix_changed[i][j])
        # print(emission_matrix_changed[j][t+1])
        upper_part = upper_part + all_multiplied
        # upper_part = upper_part + np.exp(all_multiplied)
        # print(all_multiplied , "-->" , np.exp(all_multiplied))

        all_calculated = alpha_incoming[i][t] * (beta_incoming[i][t] / coefficients[t])
        # all_calculated = np.log(alpha_incoming[i][t]) + np.log(beta_incoming[i][t]) - np.log(coefficients[t])
        lower_part = lower_part + all_calculated
        # lower_part = lower_part + np.exp(all_calculated)

      # print(upper_part , "/" , lower_part)
      transition_matrix_changed[i][j] = upper_part / lower_part

  pi_star = np.array([[float(0)]*length]*N)

  pi_star = alpha_incoming * beta_incoming
  # print(pi_star)

  # for i in pi_star:
  #   for j in i:
  #     if j==0.0:
  #       print("bingo")

  for i in range(length):
    pi_star[: , i] = pi_star[: , i] / np.sum(pi_star[: , i])

  # print(pi_star)
  # print(np.sum(pi_star[0]))

  for k in range(N):
    means_changed[k] = np.sum(pi_star[k] * np.array(observations)) / np.sum(pi_star[k])

  # print(means_changed)

  for k in range(N):
    the_minus = np.array(observations) - means_changed[k]
    # print(observations)
    # print(the_minus)
    squared = np.power(the_minus , 2)
    # print(squared)
    # print(np.sum(pi_star[k]))
    standard_deviations_changed[k] = np.sqrt(np.sum(pi_star[k] * squared) / np.sum(pi_star[k]))

  # print(standard_deviations_changed)

  emission_matrix_changed.clear()
  for state in states:
    one_row_again = []
    for observation in observations:
        # probability = gaussian_distribution(observation , means_changed[state] , standard_deviations_changed[state])
        probability = gaussian_distribution2(observation , means_changed[state] , standard_deviations_changed[state])
        if probability==0.0:
            probability = 1e-323
        one_row_again.append(probability)
    
    emission_matrix_changed.append(one_row_again)

  # print(emission_matrix_changed)

# for i in range(20):
# update_phase()
# transition_matrix = transition_matrix_changed
# alpha_incoming = forward_phase()
# beta_incoming = backward_phase()
tracker = 0

for i in range(20):
  eigen_values, eigen_vectors = la.eig(transition_matrix_changed , left=True , right=False)
  initial_probabilities = eigen_vectors[: , np.isclose(eigen_values , 1)]
  initial_probabilities = initial_probabilities[:,0]
  pi_vector2 = initial_probabilities / initial_probabilities.sum()
  # print(pi_vector2)

  transition_matrix_before = np.array(transition_matrix_changed)
  means_before = np.copy(means_changed)
  standard_deviation_before = np.copy(standard_deviations_changed)

  alpha_incoming = forward_phase(transition_matrix_changed , pi_vector2 , emission_matrix_changed)
  beta_incoming = backward_phase(transition_matrix_changed , emission_matrix_changed)
  update_phase(alpha_incoming , beta_incoming)
  # print(transition_matrix_changed)
  tracker += 1

  transition_matrix_after = np.array(transition_matrix_changed)
  means_after = np.copy(means_changed)
  standard_deviation_after = np.copy(standard_deviations_changed)
  # print(transition_matrix_before)
  # print(transition_matrix_after)
  # print(means_before)
  # print(means_after)
  # print(standard_deviation_before)
  # print(standard_deviation_after)
  flag_transition_matrix = False
  flag_means = False
  flag_standard_deviation = False

  if np.amax(np.abs(transition_matrix_after - transition_matrix_before)) < 1e-15:
    flag_transition_matrix = True

  if np.amax(np.abs(means_after - means_before)) < 1e-15:
    flag_means = True

  if np.amax(np.abs(standard_deviation_after - standard_deviation_before)) < 1e-15:
    flag_standard_deviation = True

  if flag_transition_matrix and flag_means and flag_standard_deviation:
    break

print(transition_matrix_changed)
print(pi_vector2)
# print(emission_matrix_changed)
print(means_changed)
print(np.power(standard_deviations_changed , 2))
print(tracker)

filename = 'parameters_learned.txt'
f = open(filename, "w")
f.write(str(N) + '\n')
for i in states:
    for j in states:
        f.write(str(transition_matrix_changed[i][j]) + "\t")
    
    f.write("\n")

for i in states:
    f.write(str(means_changed[i]) + "\t")

f.write("\n")

for i in states:
    f.write(str(standard_deviations_changed[i] * standard_deviations_changed[i]) + "\t")
    # f.write(str(standard_deviations_changed[i]) + "\t")

f.write("\n")

for i in states:
    f.write(str(pi_vector[i]) + "\t")

f.write("\n")

f.close()

# en_values, eigen_vectors = la.eig(transition_matrix_changed , left=True , right=False)
# initial_probabilities = eigen_vectors[: , np.isclose(eigen_values , 1)]
# initial_probabilities = initial_probabilities[:,0]
# pi_vector2 = initial_probabilities / initial_probabilities.sum()
# print(pi_vector2)


sequence = viterbi(observations, states, pi_vector2, transition_matrix_changed, emission_matrix_changed)

filename = 'states_Viterbi_after_learning.txt'

f = open(filename, "w")

one, zero = 0, 0
for s in sequence:
    if(s == 0):
        #print('"El Nino"')
        f.write('\"El Nino\"\n')
        zero += 1
    else:
        #print('"La Nina"')
        f.write('\"La Nina\"\n')
        one += 1

print(zero, one)
print(len(sequence))

f.close()

# norm.pdf(98 , loc=100 , scale=12)
# Q = np.array([
#     [.95, .05, 0., 0.],
#     [0., 0.9, 0.09, 0.01],
#     [0., 0.05, 0.9, 0.05],
#     [0.8, 0., 0.05, 0.15]])

# #evals, evecs = np.linalg.eig(Q.T)
# evals, evecs = la.eig(Q , left =True , right=False)
# print(evals)
# print(evecs)
# print(np.isclose(evals, 1))
# evec1 = evecs[:,np.isclose(evals, 1)]
# #evec2 = evecs[: , 0]
# print(evec1)
# #print(evec2)

# evec1 = evec1[:,0]
# print(evec1)

# stationary = evec1 / evec1.sum()
# print(stationary)

# alpha_matrix = np.array([[1.0]*10]*2)
# x = 1.0 / np.sum(alpha_matrix[: , 0])
# x

# x = np.exp(np.log(10))
# x

# a = np.array([[2.0,3.0] , [1.0,2.0]])
# # b=a*a
# # b
# a[: , 0] = a[: , 0] / np.sum(a[: , 0])
# a[: , 1] = a[: , 1] / np.sum(a[: , 1])
# a

# a = np.array([1,2,3,4])
# b = a - 1
# b